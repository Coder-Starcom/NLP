{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ What is FastText?\n",
    "\n",
    "**FastText** is a lightweight and fast library developed by Facebook AI for:\n",
    "\n",
    "* üî§ **Text classification** (e.g., sentiment, topic tagging)\n",
    "* üß† **Word embeddings** (like Word2Vec, but with subword info)\n",
    "\n",
    "It's known for being:\n",
    "\n",
    "* **Very fast to train**\n",
    "* **Accurate**, especially for small datasets\n",
    "* Useful even with limited compute\n",
    "\n",
    "In this example, you‚Äôre doing **supervised text classification**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/facebookresearch/fastText/archive/0.2.0.zip\n",
    "# !unzip 0.2.0.zip\n",
    "# %cd fastText-0.2.0\n",
    "# !make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Alternate)üì¶ Step 1: Download and Build FastText\n",
    "\n",
    "```python\n",
    "!wget https://github.com/facebookresearch/fastText/archive/0.2.0.zip\n",
    "!unzip 0.2.0.zip\n",
    "%cd fastText-0.2.0\n",
    "!make\n",
    "```\n",
    "\n",
    "* `wget`: Downloads the FastText source code (v0.2.0)\n",
    "* `unzip`: Extracts the archive\n",
    "* `%cd`: Changes directory (Colab magic command)\n",
    "* `make`: Compiles the C++ source code, producing the binary `./fasttext`\n",
    "\n",
    "‚úÖ After this step, you have a working `./fasttext` CLI tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALMQ3gjFqqZS"
   },
   "outputs": [],
   "source": [
    "# 1 is positive, 0 is negative\n",
    "f = open('train.txt', 'w')\n",
    "f.write('__label__1 i love you\\n')\n",
    "f.write('__label__1 he loves me\\n')\n",
    "f.write('__label__1 she likes baseball\\n')\n",
    "f.write('__label__0 i hate you\\n')\n",
    "f.write('__label__0 sorry for that\\n')\n",
    "f.write('__label__0 this is awful')\n",
    "f.close()\n",
    "\n",
    "f = open('test.txt', 'w')\n",
    "f.write('sorry hate you')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìù Step 2: Create Training Data\n",
    "\n",
    "```python\n",
    "f = open('train.txt', 'w')\n",
    "f.write('__label__1 i love you\\n')\n",
    "f.write('__label__1 he loves me\\n')\n",
    "f.write('__label__1 she likes baseball\\n')\n",
    "f.write('__label__0 i hate you\\n')\n",
    "f.write('__label__0 sorry for that\\n')\n",
    "f.write('__label__0 this is awful')\n",
    "f.close()\n",
    "```\n",
    "\n",
    "* This is a **sentiment classification dataset**.\n",
    "* Format: `__label__<label> <text>`\n",
    "\n",
    "FastText expects:\n",
    "\n",
    "* Each line to be a labeled example.\n",
    "* Labels to be prefixed by `__label__`.\n",
    "\n",
    "So here:\n",
    "\n",
    "* `__label__1` ‚Üí Positive\n",
    "* `__label__0` ‚Üí Negative\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß™ Step 3: Create Test File\n",
    "\n",
    "```python\n",
    "f = open('test.txt', 'w')\n",
    "f.write('sorry hate you')\n",
    "f.close()\n",
    "```\n",
    "\n",
    "* One test sentence.\n",
    "* No labels; we want FastText to predict them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 92
    },
    "colab_type": "code",
    "id": "q06m76JusOQ8",
    "outputId": "4ed3502d-4aec-4d06-cb02-b8392978ce14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'.' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "! ./fasttext supervised -input train.txt -output model -dim 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† Step 4: Train the Model\n",
    "\n",
    "```bash\n",
    "!./fasttext supervised -input train.txt -output model -dim 2\n",
    "```\n",
    "\n",
    "This trains a **supervised text classifier**.\n",
    "\n",
    "| Option       | Explanation                                         |\n",
    "| ------------ | --------------------------------------------------- |\n",
    "| `supervised` | Train a text classifier (vs. `skipgram`, etc.)      |\n",
    "| `-input`     | File with labeled training data                     |\n",
    "| `-output`    | Prefix for saved model files (model.bin, model.vec) |\n",
    "| `-dim 2`     | Embedding dimension (just 2 here for simplicity)    |\n",
    "\n",
    "‚úÖ After training, FastText saves:\n",
    "\n",
    "* `model.bin` ‚Üí Trained binary model\n",
    "* `model.vec` ‚Üí Word embeddings (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "colab_type": "code",
    "id": "y1yDPCjVsO6x",
    "outputId": "8963d7bd-01c8-40b9-e1ee-1446cb1b3454"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cat' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'.' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!cat test.txt\n",
    "!./fasttext predict model.bin test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üì§ Step 5: Run Inference\n",
    "\n",
    "```bash\n",
    "!cat test.txt\n",
    "!./fasttext predict model.bin test.txt\n",
    "```\n",
    "\n",
    "* `cat test.txt` shows the sentence: `sorry hate you`\n",
    "* `fasttext predict` loads the model and predicts the label\n",
    "\n",
    "üìå Expected output:\n",
    "\n",
    "```\n",
    "__label__0\n",
    "```\n",
    "\n",
    "Because:\n",
    "\n",
    "* ‚Äúsorry‚Äù, ‚Äúhate‚Äù, ‚Äúyou‚Äù all occurred in negative examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ Summary\n",
    "\n",
    "| Step              | Purpose                                     |\n",
    "| ----------------- | ------------------------------------------- |\n",
    "| üèó Build FastText | Compiles the library in your notebook       |\n",
    "| üìù Train.txt      | Labeled training data for classification    |\n",
    "| üß™ Test.txt       | Input file for prediction                   |\n",
    "| ‚öôÔ∏è Train model    | Learns word embeddings + classifier         |\n",
    "| üîÆ Predict        | Uses learned model to classify new sentence |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fasttext_label_with_prob(model_path, input_text, tmp_file='tmp_input.txt', k=1):\n",
    "    import subprocess\n",
    "\n",
    "    # Save input to file\n",
    "    with open(tmp_file, 'w') as f:\n",
    "        f.write(input_text.strip())\n",
    "\n",
    "    # Run fasttext predict-prob\n",
    "    result = subprocess.run(\n",
    "        ['./fasttext', 'predict-prob', model_path, tmp_file, str(k)],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        print(\"‚ö†Ô∏è Error:\", result.stderr)\n",
    "        return []\n",
    "\n",
    "    predictions = []\n",
    "    for line in result.stdout.strip().split('\\n'):\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.strip().split()\n",
    "        # FastText may return multiple predictions per line\n",
    "        for i in range(0, len(parts), 2):\n",
    "            try:\n",
    "                label = parts[i]\n",
    "                prob = float(parts[i + 1])\n",
    "                predictions.append((label, prob))\n",
    "            except (IndexError, ValueError):\n",
    "                continue  # skip malformed entries\n",
    "\n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33mthis is amazing\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m predictions = predict_fasttext_label_with_prob(\u001b[33m'\u001b[39m\u001b[33mmodel.bin\u001b[39m\u001b[33m'\u001b[39m, text, k=\u001b[32m2\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m label, confidence \u001b[38;5;129;01min\u001b[39;00m predictions:\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müîç \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with confidence \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfidence\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mpredict_fasttext_label_with_prob\u001b[39m\u001b[34m(model_path, input_text, tmp_file, k)\u001b[39m\n\u001b[32m      6\u001b[39m     f.write(input_text.strip())\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Run fasttext predict-prob\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m result = subprocess.run(\n\u001b[32m     10\u001b[39m     [\u001b[33m'\u001b[39m\u001b[33m./fasttext\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mpredict-prob\u001b[39m\u001b[33m'\u001b[39m, model_path, tmp_file, \u001b[38;5;28mstr\u001b[39m(k)],\n\u001b[32m     11\u001b[39m     stdout=subprocess.PIPE,\n\u001b[32m     12\u001b[39m     stderr=subprocess.PIPE,\n\u001b[32m     13\u001b[39m     text=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     14\u001b[39m )\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.returncode != \u001b[32m0\u001b[39m:\n\u001b[32m     17\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚ö†Ô∏è Error:\u001b[39m\u001b[33m\"\u001b[39m, result.stderr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects\\NLP\\env\\Lib\\subprocess.py:554\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    551\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m    552\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    556\u001b[39m         stdout, stderr = process.communicate(\u001b[38;5;28minput\u001b[39m, timeout=timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects\\NLP\\env\\Lib\\subprocess.py:1039\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1035\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1036\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1037\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     \u001b[38;5;28mself\u001b[39m._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[32m   1040\u001b[39m                         pass_fds, cwd, env,\n\u001b[32m   1041\u001b[39m                         startupinfo, creationflags, shell,\n\u001b[32m   1042\u001b[39m                         p2cread, p2cwrite,\n\u001b[32m   1043\u001b[39m                         c2pread, c2pwrite,\n\u001b[32m   1044\u001b[39m                         errread, errwrite,\n\u001b[32m   1045\u001b[39m                         restore_signals,\n\u001b[32m   1046\u001b[39m                         gid, gids, uid, umask,\n\u001b[32m   1047\u001b[39m                         start_new_session, process_group)\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1049\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1050\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Projects\\NLP\\env\\Lib\\subprocess.py:1554\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[39m\n\u001b[32m   1552\u001b[39m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[32m   1553\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1554\u001b[39m     hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n\u001b[32m   1555\u001b[39m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[32m   1556\u001b[39m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1557\u001b[39m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[32m   1558\u001b[39m                              creationflags,\n\u001b[32m   1559\u001b[39m                              env,\n\u001b[32m   1560\u001b[39m                              cwd,\n\u001b[32m   1561\u001b[39m                              startupinfo)\n\u001b[32m   1562\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1563\u001b[39m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[32m   1564\u001b[39m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1567\u001b[39m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[32m   1568\u001b[39m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[32m   1569\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_pipe_fds(p2cread, p2cwrite,\n\u001b[32m   1570\u001b[39m                          c2pread, c2pwrite,\n\u001b[32m   1571\u001b[39m                          errread, errwrite)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "text = \"this is amazing\"\n",
    "predictions = predict_fasttext_label_with_prob('model.bin', text, k=2)\n",
    "\n",
    "for label, confidence in predictions:\n",
    "    print(f\"üîç {label} with confidence {confidence:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FastText.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
